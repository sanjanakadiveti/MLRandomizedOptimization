import matplotlib.pyplot as plt

# genetic algorithms
trainErr = [10.624192297751364,10.299302145257172,10.528818816231578,9.887567846988887,9.243887309382268,8.682605324373213,7.909356422848288,8.130007753941584]
testErr = [13.54597527886645,13.163702140488397,14.07265601447091,12.75128127826349,12.916792282182683,11.751884232740423,12.973168525776302,13.2378956888755]
popSizes = [50,100,150,200,250,300,350,400]

plt.figure()
plt.title('Genetic Algorithms: Performance x Population Size')
plt.rc('legend',**{'fontsize':10})
plt.plot(popSizes, trainErr, '-', marker='o', label='train error')
plt.plot(popSizes, testErr, '-', marker='o', label='test error')
plt.legend()
plt.xlabel('Population Size')
plt.ylabel('Sum of Squared Error')
plt.ylim(0, 20)
plt.show()

trainErr = [8.026, 7.58, 7.67, 8.11]
testErr = [11.762224902019904,
10.87912270123605,
11.171781730479347,
12.29490503466987]
mute = [25, 50, 75, 100]
plt.figure()
plt.title('Genetic Algorithms: Performance x ToMate')
plt.rc('legend',**{'fontsize':10})
plt.plot(mute, trainErr, '-', marker='o', label='train error')
plt.plot(mute, testErr, '-', marker='o', label='test error')
plt.legend()
plt.xlabel('To Mate')
plt.ylim(0, 20)
plt.ylabel('Sum of Squared Error')
plt.show()

iterations = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000]

train = [16.890669423623677,
11.630912380460074,
11.488756784698879,
10.739209097958124,
9.679503747738437,
8.929956060997682,
7.883173946756273,
9.07211165675885,
8.245024554148358,
8.503489273714138,
8.593951925562166,
8.41302662186611,
8.529335745670721,
7.624709227190479,
8.038252778495732,
8.581028689583874,
7.857327474799689,
8.064099250452315,
7.779788058929967,
7.405014215559575]

test = [21.495327102803742,
14.410611998794082,
11.878203195658728,
18.20922520349714,
12.842930358757911,
12.601748567983122,
12.209828157974073,
11.395839614109136,
11.154657823334333,
11.094362375640642,
11.938498643352418,
13.747362074163405,
13.898100693397652,
9.978896593307212,
10.702441965631593,
14.229725655712997,
9.436237564063916,
11.395839614109136,
10.099487488694606,
12.270123605667777]


trainTime = [0.082255787,
0.044149531,
0.039484803,
0.068917666,
0.043511049,
0.046074117,
0.042292765,
0.040629244,
0.044104913,
0.054668046,
0.05714574,
0.043870057,
0.046560524,
0.047321208,
0.041507908,
0.04213636,
0.119920988,
0.041255408,
0.039867974,
0.040740654]

testTime = [0.109403044,
0.020318885,
0.017556152,
0.019637348,
0.017522329,
0.016565862,
0.022436721,
0.017967784,
0.019204987,
0.022795007,
0.0207096,
0.017806951,
0.016359963,
0.031894431,
0.0162162,
0.01657642,
0.069994819,
0.022288687,
0.021223593,
0.021202051]

plt.figure()
plt.title('Genetic Algorithms: Performance x Iterations')
plt.rc('legend',**{'fontsize':10})
plt.plot(iterations, train, '-', label='train error')
plt.plot(iterations, test, '-', label='test error')
plt.legend()
plt.xlabel('Iterations')
plt.ylabel('Sum of Squared Error')
plt.ylim(0, 50)
plt.show()
#
# train_error = [7.702, 7.172, 7.819, 9.408, 10.894, 13.272]
# test_error = [11.876, 11.393, 23.162, 16.853, 21.676, 41.93]
# iterations = [10, 8, 5, 3, 2, 1]
# plt.figure()
# plt.title('Randomized Hill Climbing: Performance x Random Restarts')
# plt.rc('legend',**{'fontsize':10})
# plt.plot(iterations, train_error, '-', label='train error')
# plt.plot(iterations, test_error, '-', label='test error')
# plt.legend()
# plt.xlabel('Number of Restarts')
# plt.ylabel('Sum of Squares Error')
# plt.show()
#
# # rhc
# train_error = [29.32282243473766,
# 24.79968984233652,
# 23.507366244507622,
# 23.95967950374775,
# 13.07831481002843,
# 9.86042905143448,
# 14.629103127423107,
# 10.648746446110096,
# 8.232101318170066,
# 8.981649004910835,
# 7.870250710777981,
# 9.563194623933839,
# 7.547169811320757,
# 7.560093047299048,
# 7.4308606875161445,
# 6.745929180666849,
# 7.069010080124059,
# 6.332385629361596,
# 6.151460325665553,
# 6.526234169035931]
# test_error = [43.74434730177872,
# 26.89176967138981,
# 31.564666867651496,
# 28.097678625263782,
# 14.380464274947244,
# 12.692191739523665,
# 24.178474525173357,
# 19.053361471208916,
# 10.913476032559544,
# 11.395839614109136,
# 13.626771178775996,
# 17.907747965028648,
# 11.275248718721741,
# 13.626771178775996,
# 11.998794091046122,
# 11.51643050949653,
# 10.581851070244198,
# 12.903225806451616,
# 10.943623756406396,
# 10.61199879409105]
# iterations = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000]
# #
# plt.figure()
# plt.title('Randomized Hill Climbing: Performance x Iterations')
# plt.rc('legend',**{'fontsize':10})
# plt.plot(iterations, train_error, '-', label='train error')
# plt.plot(iterations, test_error, '-', label='test error')
# plt.legend()
# plt.xlabel('Iterations')
# plt.ylabel('Sum of Squares Error')
# plt.show()
#
# train_error = [7.740, 6.358, 6.319, 6.789, 7.604, 6.811, 6.164, 6.292]
# test_error = [9.92, 8.803, 9.16, 9.83, 9.98, 10.33, 9.225, 9.461]
# iterations = [1, 2, 3, 5, 8, 10, 15, 20]
# plt.figure()
# plt.title('Randomized Hill Climbing: Performance x Random Restarts')
# plt.rc('legend',**{'fontsize':10})
# plt.plot(iterations, train_error, '-', label='train error')
# plt.plot(iterations, test_error, '-', label='test error')
# plt.legend()
# plt.xlabel('Number of Restarts')
# plt.ylabel('Sum of Squares Error')
# plt.show()
# #
train = [7.676402171103646,7.305634530886536,6.952416645127931,7.175781855776685,7.568105453605583,7.802868958387177,7.288705091754977]
test = [11.353271028037392,10.903225806451616,10.073861923424786,9.003919204100086,9.149532710280369,9.33415737111849,10.139975881820925]
temps = [6, 7, 8, 9, 10, 11, 12]
#
plt.figure()
plt.title('SA: Performance x Temperature')
plt.rc('legend',**{'fontsize':10})
plt.plot(temps, train, '-', marker = 'o',label='train error')
plt.plot(temps, test, '-', marker = 'o',label='test error')
plt.legend()
plt.xlabel('Temperature (10^x)')
plt.ylabel('Sum of Squared Error')
plt.ylim(0,20)
plt.show()


train = [7.095, 7.14, 7.085, 7.108, 7.353, 7.492, 7.573, 7.534, 7.56, 7.76]
test = [9.305,10.119, 9.903, 9.105, 10.33, 10.612, 10.034, 10.21, 10.52, 11.28]
cooling = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
plt.figure()
plt.title('SA: Performance x Cooling')
plt.rc('legend',**{'fontsize':10})
plt.plot(cooling, train, '-', marker = 'o',label='train error')
plt.plot(cooling, test, '-', marker = 'o',label='test error')
plt.legend()
plt.xlabel('Cooling')
plt.ylabel('Sum of Squared Error')
plt.ylim(0,20)
plt.show()


train = [51.07262858619798,30.718531920392863,21.271646420263636,22.383044714396476,11.07521323339364,11.915223571982423,10.157663478935135,9.498578444042394,10.261049366761426,10.868441457741014,10.002584647195661,7.857327474799689,8.270871026104928,6.526234169035931,6.862238304471433,7.120703024037226,6.513310933057639,7.314551563711561,7.1594727319720874,5.944688550012927]

test = [45.37232438950859,27.524871872173648,29.394030750678326,30.117576123002706,16.49080494422671,14.13928248417244,19.74675911968646,17.515827555019598,13.264998492613813,14.470907446487786,15.043714199577934,11.06421465179379,12.601748567983122,9.617123907145015,10.762737413325297,9.918601145613508,11.456135061802826,12.119384986433516,10.129635212541459,9.496533011757606]

trainTime = [2.371100701E9,4.697774622E9,6.896455702E9,9.190962856E9,1.35420295E10,1.4424564594E10,1.9584156437E10,1.8300754672E10,2.0040076174E10,2.4601540798E10,2.5086255908E10,2.7076756386E10,3.1250287911E10,3.2992264052E10,3.5369442908E10,3.8172198331E10,4.4767067078E10,4.1745541375E10,4.3076691182E10,4.6777985114E10]

testTime = [0.12336665,0.053339061,0.023369747,0.036529618,0.037967693,0.01645676,0.024788326,0.016425826,0.016740957,0.038668126,0.01604022,0.019713523,0.017320145,0.016724479,0.021485312,0.029523327,0.015881688,0.015395387,0.018091462,0.020571802]

iterations = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000]

plt.figure()
plt.title('SA Test: Performance x Iterations')
plt.rc('legend',**{'fontsize':10})
plt.plot(iterations, train, '-', label='train error')
plt.plot(iterations, test, '-', label='test error')
plt.legend()
plt.xlabel('Iterations')
plt.ylabel('Sum of Squared Error')
plt.show()

rhc = [35.695, 41.302, 47.573, 44.136, 51.583, 34.907]
